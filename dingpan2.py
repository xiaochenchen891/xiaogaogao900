# app.py
import streamlit as st
import pandas as pd
import numpy as np
import time
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import urllib.parse
import os
import tempfile
import warnings
from scipy import stats
import logging
import shutil
import io
import re
warnings.filterwarnings('ignore')

# è®¾ç½® logging é…ç½®
logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')

# ====================== é¡µé¢é…ç½® ======================
st.set_page_config(
    page_title="åŒèŠ±é¡ºé—®è´¢ç›‘æ§ç³»ç»Ÿ",
    page_icon="ğŸ“ˆ",
    layout="wide"
)
st.title("åŒèŠ±é¡ºé—®è´¢è‚¡ç¥¨ç›‘æ§ç³»ç»Ÿ")
st.markdown("---")

# ====================== StockMonitor ç±» ======================
class StockMonitor:
    def __init__(self):
        self.driver = None
        self.download_dir = tempfile.mkdtemp()
        self.profile_dir = tempfile.mkdtemp()
        # å›ºåŒ–åŒ¹é…ç¼“å­˜
        self.cached_selectors = {
            'search_box': {
                'selector': "//textarea[contains(@placeholder,'è¯·è¾“å…¥')]",
                'description': "æœç´¢æ¡† - è¯·è¾“å…¥æ¦‚å¿µã€ä»·å‡é‡ç¼©ç­‰ï¼Œå¤šä¸ªæ¡",
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            'search_button': {
                'selector': "//*[contains(@class,'search-icon')]",
                'description': "æœç´¢æŒ‰é’® - æ— æ–‡æœ¬",
                'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            },
            'download_button': None
        }
        # ç›‘æ§æ•°æ®å­˜å‚¨
        self.monitoring_data = {
            'timestamps': [],
            'stock_counts': [],
            'stock_lists': [],
            'slope_data': []
        }
        # ç›‘æ§çŠ¶æ€
        self.is_monitoring = False
        self.last_execution_time = None
        self.next_execution_time = None
        self.monitoring_interval = 5
        self.cycle_count = 1
        # å»¶è¿Ÿåˆå§‹åŒ–æµè§ˆå™¨
        self.driver_initialized = False
        # ç™»å½•çŠ¶æ€
        self.is_logged_in = False
        self.login_attempted = False
        # ä¸‹è½½å†å²
        self.last_download_time = None
        self.downloaded_files_history = []
        # å€’è®¡æ—¶
        self.countdown_seconds = 0

    # ==================== ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ç®¡ç†æµè§ˆå™¨é©±åŠ¨ ====================
    def initialize_driver(self):
        if self.driver_initialized and self.driver:
            logging.debug("æ­¥éª¤: Driver already initialized.")
            return True
        
        try:
            # é¦–å…ˆå°è¯•ä½¿ç”¨ Chrome
            return self.initialize_chrome_with_manager()
        except Exception as e:
            logging.error(f"Chrome initialization failed: {str(e)}")
            try:
                # å¦‚æœ Chrome å¤±è´¥ï¼Œå°è¯• Edge
                return self.initialize_edge_with_manager()
            except Exception as e2:
                logging.error(f"Edge initialization also failed: {str(e2)}")
                st.error(f"æ‰€æœ‰æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ã€‚é”™è¯¯: {str(e)}")
                return False

    def initialize_chrome_with_manager(self):
        """ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ç®¡ç† Chrome é©±åŠ¨"""
        try:
            logging.debug("æ­¥éª¤: Initializing Chrome with webdriver-manager...")
            
            from selenium.webdriver.chrome.options import Options as ChromeOptions
            from selenium.webdriver.chrome.service import Service as ChromeService
            from webdriver_manager.chrome import ChromeDriverManager
            
            chrome_options = ChromeOptions()
            
            # åŸºæœ¬é…ç½®
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            chrome_options.add_experimental_option('useAutomationExtension', False)
            
            # ç”¨æˆ·æ•°æ®ç›®å½•é…ç½®
            if self.profile_dir:
                chrome_options.add_argument(f'--user-data-dir={self.profile_dir}')
            
            # æ€§èƒ½ä¼˜åŒ–å‚æ•°
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-extensions')
            chrome_options.add_argument('--disable-plugins')
            
            # ä¸‹è½½é…ç½®
            prefs = {
                "download.default_directory": self.download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": False,
                "profile.default_content_settings.popups": 0,
            }
            chrome_options.add_experimental_option("prefs", prefs)
            
            # ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç† ChromeDriver
            service = ChromeService(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            
            self.driver.maximize_window()
            self.driver.implicitly_wait(5)
            self.driver_initialized = True
            logging.debug("æ­¥éª¤: Chrome driver initialized successfully with webdriver-manager.")
            st.success("âœ… å·²æˆåŠŸä½¿ç”¨ Chrome æµè§ˆå™¨")
            return True
            
        except Exception as e:
            logging.error(f"Error initializing Chrome with webdriver-manager: {str(e)}")
            raise e

    def initialize_edge_with_manager(self):
        """ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ç®¡ç† Edge é©±åŠ¨"""
        try:
            logging.debug("æ­¥éª¤: Initializing Edge with webdriver-manager...")
            
            from selenium.webdriver.edge.options import Options as EdgeOptions
            from selenium.webdriver.edge.service import Service as EdgeService
            from webdriver_manager.microsoft import EdgeChromiumDriverManager
            
            edge_options = EdgeOptions()
            
            # åŸºæœ¬é…ç½®
            edge_options.add_argument('--no-sandbox')
            edge_options.add_argument('--disable-dev-shm-usage')
            edge_options.add_argument('--disable-blink-features=AutomationControlled')
            edge_options.add_experimental_option("excludeSwitches", ["enable-automation"])
            edge_options.add_experimental_option('useAutomationExtension', False)
            
            # ç”¨æˆ·æ•°æ®ç›®å½•é…ç½®
            if self.profile_dir:
                edge_options.add_argument(f'--user-data-dir={self.profile_dir}')
            
            # æ€§èƒ½ä¼˜åŒ–å‚æ•°
            edge_options.add_argument('--disable-gpu')
            edge_options.add_argument('--disable-extensions')
            edge_options.add_argument('--disable-plugins')
            
            # ä¸‹è½½é…ç½®
            prefs = {
                "download.default_directory": self.download_dir,
                "download.prompt_for_download": False,
                "download.directory_upgrade": True,
                "safebrowsing.enabled": False,
                "profile.default_content_settings.popups": 0,
            }
            edge_options.add_experimental_option("prefs", prefs)
            
            # ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç† EdgeDriver
            service = EdgeService(EdgeChromiumDriverManager().install())
            self.driver = webdriver.Edge(service=service, options=edge_options)
            
            self.driver.maximize_window()
            self.driver.implicitly_wait(5)
            self.driver_initialized = True
            logging.debug("æ­¥éª¤: Edge driver initialized successfully with webdriver-manager.")
            st.success("âœ… å·²æˆåŠŸä½¿ç”¨ Edge æµè§ˆå™¨")
            return True
            
        except Exception as e:
            logging.error(f"Error initializing Edge with webdriver-manager: {str(e)}")
            raise e

    # ==================== ç®€åŒ–çš„å¯¼èˆªæ–¹æ³• ====================
    def ensure_navigation(self, force_refresh=False):
        if not self.initialize_driver():
            logging.error("æ­¥éª¤: Failed to initialize driver for navigation.")
            st.error("âŒ æµè§ˆå™¨åˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡º")
            return False
        
        try:
            logging.debug("æ­¥éª¤: Ensuring navigation...")
            target_url = "https://www.iwencai.com/unifiedwap/"
            
            # ç®€åŒ–å¯¼èˆªé€»è¾‘
            if force_refresh:
                logging.debug(f"æ­¥éª¤: Force refreshing to {target_url}")
                self.driver.get(target_url)
            else:
                current_url = self.driver.current_url
                if target_url not in current_url:
                    logging.debug(f"æ­¥éª¤: Navigating to {target_url}")
                    self.driver.get(target_url)
            
            # æ›´å®½æ¾çš„ç­‰å¾…æ¡ä»¶
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.TAG_NAME, "body"))
            )
            
            logging.debug("æ­¥éª¤: Navigation successful.")
            return True
            
        except Exception as e:
            logging.error(f"Error in navigation: {str(e)}")
            st.error(f"âŒ å¯¼èˆªå¤±è´¥: {str(e)}")
            return False

    # ==================== ç®€åŒ–çš„ç™»å½•å¤„ç† ====================
    def handle_login_smartly(self):
        """ç®€åŒ–çš„ç™»å½•å¤„ç†"""
        try:
            logging.debug("æ­¥éª¤: Checking for login requirement...")
            
            # ç®€åŒ–çš„ç™»å½•æ£€æµ‹
            login_indicators = [
                "//div[contains(text(), 'æ‰«ç ç™»å½•')]",
                "//div[contains(@class, 'login')]",
                "//div[contains(@class, 'qrcode')]",
            ]
            
            # å¿«é€Ÿæ£€æŸ¥
            for selector in login_indicators:
                try:
                    elements = self.driver.find_elements(By.XPATH, selector)
                    for element in elements:
                        if element.is_displayed():
                            logging.debug(f"æ­¥éª¤: Login popup detected with: {selector}")
                            return self.wait_for_login_completion()
                except:
                    continue
            
            logging.debug("æ­¥éª¤: No login required.")
            return True
            
        except Exception as e:
            logging.error(f"Error in login handling: {str(e)}")
            return False

    def wait_for_login_completion(self, timeout=120):
        """ç­‰å¾…ç™»å½•å®Œæˆ"""
        logging.debug("æ­¥éª¤: Waiting for login completion...")
        
        start_time = time.time()
        while time.time() - start_time < timeout:
            # æ£€æŸ¥ç™»å½•å¼¹çª—æ˜¯å¦è¿˜å­˜åœ¨
            login_visible = False
            try:
                login_elements = self.driver.find_elements(By.XPATH, "//div[contains(text(), 'æ‰«ç ç™»å½•')]")
                for element in login_elements:
                    if element.is_displayed():
                        login_visible = True
                        break
            except:
                pass
            
            if not login_visible:
                self.is_logged_in = True
                logging.debug("æ­¥éª¤: Login completed successfully.")
                time.sleep(2)  # ç­‰å¾…é¡µé¢ç¨³å®š
                return True
            
            time.sleep(2)
        
        logging.warning("æ­¥éª¤: Login timeout.")
        return False

    # ==================== æ”¹è¿›çš„ä¸‹è½½æµç¨‹ ====================
    def smart_download_flow_optimized(self):
        """æ”¹è¿›çš„ä¸‹è½½æµç¨‹"""
        try:
            logging.debug("æ­¥éª¤: Starting optimized download flow...")
            
            # è®°å½•ä¸‹è½½å¼€å§‹æ—¶é—´
            download_start_time = time.time()
            
            # é¦–å…ˆæ¸…ç©ºä¸‹è½½ç›®å½•çš„æ—§æ–‡ä»¶
            self.clean_download_directory()
            
            # æŸ¥æ‰¾ä¸‹è½½æŒ‰é’®
            btn = self.find_and_cache_download_button()
            if not btn:
                logging.error("æ­¥éª¤: Download button not found.")
                # å°è¯•å…¶ä»–é€‰æ‹©å™¨
                btn = self.find_alternative_download_button()
                if not btn:
                    return False
            
            # ç‚¹å‡»ä¸‹è½½æŒ‰é’®
            logging.debug("æ­¥éª¤: Clicking download button...")
            try:
                self.driver.execute_script("arguments[0].scrollIntoView(true);", btn)
                time.sleep(1)
                self.driver.execute_script("arguments[0].click();", btn)
            except Exception as e:
                logging.error(f"JavaScript click failed: {str(e)}")
                try:
                    btn.click()
                except Exception as e2:
                    logging.error(f"Regular click also failed: {str(e2)}")
                    return False
            
            # å¤„ç†å¯èƒ½çš„ç™»å½•
            time.sleep(3)
            if not self.is_logged_in:
                self.handle_login_smartly()
            
            # å¦‚æœç™»å½•æˆåŠŸï¼Œé‡æ–°ç‚¹å‡»ä¸‹è½½
            if self.is_logged_in:
                time.sleep(3)
                btn = self.find_and_cache_download_button()
                if btn:
                    try:
                        self.driver.execute_script("arguments[0].click();", btn)
                    except:
                        btn.click()
            
            # ç­‰å¾…ä¸‹è½½å®Œæˆï¼Œä¼ é€’å¼€å§‹æ—¶é—´
            return self.wait_for_download_complete_fast(download_start_time, timeout=60)
            
        except Exception as e:
            logging.error(f"Error in download flow: {str(e)}")
            return False

    def clean_download_directory(self):
        """æ¸…ç©ºä¸‹è½½ç›®å½•"""
        try:
            files = os.listdir(self.download_dir)
            for file in files:
                file_path = os.path.join(self.download_dir, file)
                try:
                    if os.path.isfile(file_path):
                        os.remove(file_path)
                        logging.debug(f"æ­¥éª¤: Removed old file: {file}")
                except Exception as e:
                    logging.warning(f"Could not remove file {file}: {str(e)}")
        except Exception as e:
            logging.error(f"Error cleaning download directory: {str(e)}")

    def find_alternative_download_button(self):
        """å°è¯•å…¶ä»–ä¸‹è½½æŒ‰é’®é€‰æ‹©å™¨"""
        alternative_selectors = [
            "//*[contains(@class, 'download')]",
            "//*[contains(text(), 'å¯¼å‡º')]",
            "//*[contains(text(), 'ä¸‹è½½')]",
            "//button[contains(@class, 'btn-download')]",
            "//a[contains(@class, 'download')]",
            "//span[contains(text(), 'å¯¼å‡º')]",
            "//span[contains(text(), 'ä¸‹è½½')]",
        ]
        
        for sel in alternative_selectors:
            try:
                elements = self.driver.find_elements(By.XPATH, sel)
                for element in elements:
                    if element.is_displayed() and element.is_enabled():
                        text = element.text or 'æ— æ–‡æœ¬'
                        logging.debug(f"æ­¥éª¤: Alternative download button found: {sel} - {text}")
                        return element
            except:
                continue
        
        logging.warning("æ­¥éª¤: No alternative download button found.")
        return None

    def wait_for_download_complete_fast(self, start_time, timeout=60):
        """æ”¹è¿›çš„ä¸‹è½½ç­‰å¾…æ–¹æ³•ï¼ŒåŸºäºæ—¶é—´æˆ³æ£€æµ‹æ–°æ–‡ä»¶"""
        try:
            logging.debug("æ­¥éª¤: Waiting for download...")
            # ä¸´æ—¶æ–‡ä»¶æ‰©å±•å
            temp_extensions = ['.crdownload', '.part', '.tmp', '.temp']
            
            # è®°å½•å¼€å§‹ç­‰å¾…çš„æ—¶é—´
            wait_start_time = time.time()
            
            while time.time() - wait_start_time < timeout:
                try:
                    files = os.listdir(self.download_dir)
                    logging.debug(f"æ­¥éª¤: Current files in directory: {files}")
                    
                    # éå†ä¸‹è½½ç›®å½•ä¸­çš„æ¯ä¸ªæ–‡ä»¶
                    for file in files:
                        file_path = os.path.join(self.download_dir, file)
                        
                        # è·³è¿‡ä¸´æ—¶æ–‡ä»¶
                        if any(file.endswith(ext) for ext in temp_extensions):
                            logging.debug(f"æ­¥éª¤: Skipping temp file: {file}")
                            continue
                            
                        # æ£€æŸ¥æ–‡ä»¶å¤§å°å’Œä¿®æ”¹æ—¶é—´
                        if os.path.getsize(file_path) > 0:
                            # è·å–æ–‡ä»¶çš„ä¿®æ”¹æ—¶é—´å’Œåˆ›å»ºæ—¶é—´ï¼Œå–æœ€å¤§å€¼
                            mtime = os.path.getmtime(file_path)
                            ctime = os.path.getctime(file_path)
                            file_time = max(mtime, ctime)
                            
                            # å¦‚æœæ–‡ä»¶çš„æ—¶é—´åœ¨å¼€å§‹æ—¶é—´ä¹‹åï¼Œè¯´æ˜æ˜¯æ–°ä¸‹è½½çš„æ–‡ä»¶
                            if file_time >= start_time:
                                logging.debug(f"æ­¥éª¤: Download completed with file: {file}")
                                logging.debug(f"æ­¥éª¤: File time: {file_time}, Start time: {start_time}")
                                return True
                            
                            # å¦‚æœæ–‡ä»¶æ—¶é—´æ—©äºå¼€å§‹æ—¶é—´ï¼Œä½†æ–‡ä»¶å¤§å°æœ‰å˜åŒ–ï¼Œä¹Ÿå¯èƒ½æ˜¯æ–°ä¸‹è½½çš„ï¼ˆè¦†ç›–ï¼‰
                            file_size = os.path.getsize(file_path)
                            logging.debug(f"æ­¥éª¤: File {file} - Size: {file_size}, Time: {file_time}")
                except Exception as e:
                    logging.error(f"Error checking download directory: {str(e)}")
                
                time.sleep(2)
            
            # è¶…æ—¶åæ£€æŸ¥æ˜¯å¦æœ‰ä»»ä½•æ–‡ä»¶
            files = os.listdir(self.download_dir)
            if files:
                logging.warning(f"æ­¥éª¤: Timeout but found files: {files}")
                # å³ä½¿è¶…æ—¶ï¼Œå¦‚æœæœ‰æ–‡ä»¶ä¹Ÿè¿”å›æˆåŠŸ
                for file in files:
                    file_path = os.path.join(self.download_dir, file)
                    if os.path.getsize(file_path) > 0:
                        logging.warning(f"æ­¥éª¤: Using existing file: {file}")
                        return True
                
            logging.warning("æ­¥éª¤: Download timeout.")
            return False
            
        except Exception as e:
            logging.error(f"Error waiting for download: {str(e)}")
            return False

    def find_and_cache_download_button(self):
        logging.debug("æ­¥éª¤: Searching for download button...")
        selectors = [
            "//div[contains(@class, 'item')]//div[contains(@class, 'download')]/../div[contains(@class, 'text') and text()='å¯¼æ•°æ®']",
            "//div[contains(@class, 'text') and text()='å¯¼æ•°æ®']",
            "//div[contains(@class, 'item')]//div[contains(@class, 'download')]",
            "//button[contains(text(), 'å¯¼æ•°æ®')]",
            "//span[contains(text(), 'å¯¼æ•°æ®')]",
            "//a[contains(text(), 'å¯¼æ•°æ®')]",
            "//div[contains(text(), 'å¯¼æ•°æ®')]",
        ]
        for sel in selectors:
            try:
                elements = self.driver.find_elements(By.XPATH, sel)
                for element in elements:
                    if element.is_displayed() and element.is_enabled():
                        text = element.text or 'æ— æ–‡æœ¬'
                        self.save_selector_to_cache('download_button', sel, f"ä¸‹è½½æŒ‰é’® - {text}")
                        logging.debug(f"æ­¥éª¤: Download button found: {sel}")
                        return element
            except:
                continue
        logging.warning("æ­¥éª¤: No download button found.")
        return None

    def save_selector_to_cache(self, element_type, selector, description=""):
        self.cached_selectors[element_type] = {
            'selector': selector,
            'description': description,
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }

    # ==================== ä¸€é”®è‡ªåŠ¨åŒ– ====================
    def one_click_automation_with_refresh(self, search_query):
        try:
            logging.debug("æ­¥éª¤: Starting automation...")
            
            # åˆ·æ–°é¡µé¢
            if not self.ensure_navigation(force_refresh=True):
                return False
            time.sleep(3)
            
            # æœç´¢æ“ä½œ
            if not self.find_search_box_with_cache(search_query):
                return False
            
            if not self.find_search_button_with_cache():
                return False
            time.sleep(5)
            
            # ä¸‹è½½æ“ä½œ
            if not self.smart_download_flow_optimized():
                return False
            
            logging.debug("æ­¥éª¤: Automation completed successfully.")
            return True
            
        except Exception as e:
            logging.error(f"Error in automation: {str(e)}")
            return False

    def find_search_box_with_cache(self, search_query):
        try:
            logging.debug(f"æ­¥éª¤: Filling search box: {search_query}")
            sel = self.cached_selectors['search_box']['selector']
            el = self.driver.find_element(By.XPATH, sel)
            if el.is_displayed() and el.is_enabled():
                el.click()
                time.sleep(0.5)
                el.clear()
                time.sleep(0.5)
                el.send_keys(search_query)
                logging.debug("æ­¥éª¤: Search box filled.")
                return True
        except Exception as e:
            logging.error(f"Error with search box: {str(e)}")
        return False

    def find_search_button_with_cache(self):
        try:
            logging.debug("æ­¥éª¤: Clicking search button...")
            sel = self.cached_selectors['search_button']['selector']
            el = self.driver.find_element(By.XPATH, sel)
            if el.is_displayed() and el.is_enabled():
                el.click()
                time.sleep(3)
                logging.debug("æ­¥éª¤: Search button clicked.")
                return True
        except Exception as e:
            logging.error(f"Error with search button: {str(e)}")
        return False

    # ==================== æ”¹è¿›çš„æ•°æ®å¤„ç†æ–¹æ³• - ä¿®å¤undefinedåˆ—è¯†åˆ«é—®é¢˜ ====================
    def process_downloaded_data(self):
        try:
            logging.debug("æ­¥éª¤: Processing downloaded data...")
            files = os.listdir(self.download_dir)
            logging.debug(f"æ­¥éª¤: All files in download directory: {files}")
            
            if not files:
                logging.warning("æ­¥éª¤: No files in download directory.")
                return None
            
            # æ‰¾åˆ°æœ€æ–°çš„æ–‡ä»¶
            latest_file = None
            latest_time = 0
            
            for file in files:
                file_path = os.path.join(self.download_dir, file)
                file_time = os.path.getmtime(file_path)
                if file_time > latest_time:
                    latest_time = file_time
                    latest_file = file
            
            if not latest_file:
                logging.warning("æ­¥éª¤: Could not determine latest file.")
                return None
                
            file_path = os.path.join(self.download_dir, latest_file)
            logging.debug(f"æ­¥éª¤: Processing latest file: {latest_file}")
            
            # ä½¿ç”¨æ”¹è¿›çš„æ–¹æ³•è¯»å–æ–‡ä»¶
            if latest_file.endswith('.csv'):
                df = self.read_iwencai_csv_improved(file_path)
            elif latest_file.endswith(('.xls', '.xlsx')):
                df = self.read_iwencai_excel_improved(file_path)
            else:
                df = self.auto_detect_iwencai_file_improved(file_path)
                
            if df is None or df.empty:
                logging.warning("æ­¥éª¤: Dataframe is empty or could not be read.")
                return None
                
            stock_count = len(df)
            slope_data = self.calculate_slopes_improved(df)
            
            logging.debug(f"æ­¥éª¤: Successfully processed {stock_count} stocks")
            
            return {
                'timestamp': datetime.now(),
                'stock_count': stock_count,
                'stock_list': df,
                'slopes': slope_data
            }
        except Exception as e:
            logging.error(f"Error processing data: {str(e)}")
            return None

    def read_iwencai_excel_improved(self, file_path):
        """æ”¹è¿›çš„Excelè¯»å–æ–¹æ³•ï¼Œç»“åˆä¸¤ç§æ–¹æ³•çš„ä¼˜åŠ¿"""
        try:
            # è¯»å–åŸå§‹æ•°æ®æ¥åˆ†æç»“æ„
            df_raw = pd.read_excel(file_path, header=None, nrows=10)
            logging.debug("æ­¥éª¤: Raw Excel data preview:")
            for i in range(min(10, len(df_raw))):
                logging.debug(f"Row {i}: {df_raw.iloc[i].tolist()}")
            
            # æ£€æµ‹è¡¨å¤´è¡Œæ•°
            header_rows = self.detect_header_rows(df_raw)
            logging.debug(f"æ­¥éª¤: Detected header rows: {header_rows}")
            
            # æ ¹æ®è¡¨å¤´è¡Œæ•°è¯»å–æ•°æ®
            if header_rows == 1:
                # å•è¡Œè¡¨å¤´
                df = pd.read_excel(file_path, header=0)
                df.columns = [str(c).strip() for c in df.columns]
            else:
                # å¤šè¡Œè¡¨å¤´ - ä½¿ç”¨æ‚¨æä¾›çš„æ–¹æ³•
                df_raw_full = pd.read_excel(file_path, header=None)
                header_df = df_raw_full.iloc[:header_rows].ffill(axis=1)
                
                # æ„å»ºåˆå¹¶åˆ—å
                columns = []
                current_prefix = ""
                for col in header_df.values.T:
                    col_strs = [str(x).strip() for x in col if str(x) != "nan"]
                    if len(col_strs) == 0:
                        columns.append("")
                        continue
                    
                    # è¯†åˆ«åˆ—ç±»åˆ«
                    if "æ”¶ç›˜ä»·" in col_strs[0]:
                        current_prefix = "æ”¶ç›˜ä»·"
                    elif "5æ—¥å‡çº¿" in col_strs[0] or "å‡çº¿" in col_strs[0]:
                        current_prefix = "5æ—¥å‡çº¿"
                    
                    # æå–æ—¥æœŸéƒ¨åˆ†
                    date_part = col_strs[-1] if len(col_strs) > 1 else col_strs[0]
                    
                    # æ„å»ºåˆ—å
                    if current_prefix and "undefined" in col_strs[0]:
                        merged = f"{current_prefix}_{date_part}"
                    else:
                        merged = "_".join(col_strs).strip("_")
                    columns.append(merged)
                
                # è¯»å–æ•°æ®éƒ¨åˆ†
                df = df_raw_full.iloc[header_rows:].reset_index(drop=True)
                df.columns = columns
            
            # åŸºç¡€æ•°æ®æ¸…æ´—
            df = self.basic_data_cleaning(df)
            
            logging.debug(f"æ­¥éª¤: Final columns after processing: {list(df.columns)}")
            return df
            
        except Exception as e:
            logging.error(f"Error reading improved Excel: {str(e)}")
            # å¤‡ç”¨æ–¹æ³•
            return pd.read_excel(file_path)

    def detect_header_rows(self, df_preview):
        """æ£€æµ‹è¡¨å¤´è¡Œæ•°"""
        header_keywords = ['ä»£ç ', 'åç§°', 'æ”¶ç›˜ä»·', 'è´¢åŠ¡è¯Šæ–­è¯„åˆ†', 'æ¦‚å¿µ']
        
        for i in range(min(5, len(df_preview))):
            row_text = ' '.join([str(x) for x in df_preview.iloc[i] if pd.notna(x)])
            # æ£€æŸ¥æ˜¯å¦åŒ…å«è¡¨å¤´å…³é”®è¯
            if any(keyword in row_text for keyword in header_keywords):
                # å¦‚æœæ˜¯ç¬¬ä¸€è¡Œå°±åŒ…å«å…³é”®è¯ï¼Œå¯èƒ½æ˜¯å•è¡Œè¡¨å¤´
                if i == 0:
                    return 1
                # å¦åˆ™è¿”å›æ£€æµ‹åˆ°çš„è¡Œå·ï¼ˆä»0å¼€å§‹ï¼‰
                return i + 1
        
        # é»˜è®¤è¿”å›1ï¼ˆå•è¡Œè¡¨å¤´ï¼‰
        return 1

    def basic_data_cleaning(self, df):
        """åŸºç¡€æ•°æ®æ¸…æ´—"""
        if df is None or df.empty:
            return df
        
        df_clean = df.copy()
        
        # æ¸…ç†å­—ç¬¦ä¸²åˆ—
        for col in df_clean.select_dtypes(include=['object']).columns:
            try:
                df_clean[col] = df_clean[col].astype(str).str.strip().replace({
                    'nan': np.nan, 'None': np.nan, '': np.nan
                })
            except Exception:
                pass
        
        # æ›¿æ¢å„ç§ç©ºå€¼ç¬¦å·
        replace_symbols = ["-", "â€”", "ç©ºå€¼", "null", "None", "", "NaN", "--"]
        df_clean.replace(replace_symbols, np.nan, inplace=True)
        
        # å¤„ç†æ•°å€¼åˆ—
        for col in df_clean.columns:
            if df_clean[col].dtype == object:
                try:
                    # ç§»é™¤é€—å·å’Œç©ºæ ¼
                    df_clean[col] = df_clean[col].astype(str).str.replace(',', '').str.replace(' ', '')
                except Exception:
                    pass
                try:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    df_clean[col] = pd.to_numeric(df_clean[col], errors='ignore')
                except Exception:
                    pass
        
        # ç§»é™¤å®Œå…¨ç©ºç™½çš„è¡Œå’Œåˆ—
        df_clean = df_clean.dropna(how='all')
        df_clean = df_clean.dropna(axis=1, how='all')
        
        # è¯†åˆ«è‚¡ç¥¨ä»£ç å’Œåç§°åˆ—
        df_clean = self.identify_stock_columns(df_clean)
        
        return df_clean

    def find_closing_price_columns(self, df):
        """æŸ¥æ‰¾æ”¶ç›˜ä»·åˆ—ï¼ŒåŒ…æ‹¬undefinedåˆ—"""
        close_cols = []
        
        # é¦–å…ˆæŸ¥æ‰¾æ˜ç¡®çš„æ”¶ç›˜ä»·åˆ—
        closing_keywords = ['æ”¶ç›˜ä»·', 'close', 'price']
        for col in df.columns:
            col_lower = str(col).lower()
            if any(keyword in col_lower for keyword in closing_keywords):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å€¼åˆ—
                if pd.api.types.is_numeric_dtype(df[col]):
                    close_cols.append(col)
                else:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    try:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                        if not df[col].isna().all():
                            close_cols.append(col)
                    except:
                        pass
        
        # ä¸“é—¨æŸ¥æ‰¾undefinedåˆ—ï¼ˆè¿™äº›ä¹Ÿæ˜¯æ”¶ç›˜ä»·æ•°æ®ï¼‰
        for col in df.columns:
            col_str = str(col).lower()
            if 'undefined' in col_str:
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°å€¼åˆ—
                if pd.api.types.is_numeric_dtype(df[col]):
                    close_cols.append(col)
                else:
                    # å°è¯•è½¬æ¢ä¸ºæ•°å€¼
                    try:
                        df[col] = pd.to_numeric(df[col], errors='coerce')
                        if not df[col].isna().all():
                            close_cols.append(col)
                    except:
                        pass
        
        # å¦‚æœæ”¶ç›˜ä»·åˆ—ä¸å¤Ÿï¼ŒæŸ¥æ‰¾åŒ…å«æ—¥æœŸçš„æ•°å€¼åˆ—
        if len(close_cols) < 2:
            date_pattern = r'\d{4}\.\d{2}\.\d{2}|\d{4}-\d{2}-\d{2}|\d{8}'
            for col in df.columns:
                col_str = str(col)
                if re.search(date_pattern, col_str) and pd.api.types.is_numeric_dtype(df[col]):
                    close_cols.append(col)
        
        # æŒ‰åˆ—ä½ç½®æ’åºï¼Œç¡®ä¿æ­£ç¡®çš„é¡ºåºï¼ˆä»å·¦åˆ°å³ï¼Œæœ€è¿‘çš„æ—¥æœŸåœ¨æœ€å³è¾¹ï¼‰
        close_cols.sort(key=lambda x: list(df.columns).index(x))
        
        logging.debug(f"æ­¥éª¤: Final closing price columns found: {close_cols}")
        return close_cols

    def calculate_slopes_improved(self, df):
        """æ”¹è¿›çš„æ–œç‡è®¡ç®—æ–¹æ³•ï¼Œå¢åŠ è¯¦ç»†è°ƒè¯•ä¿¡æ¯"""
        slopes = {}
        
        # æŸ¥æ‰¾æ”¶ç›˜ä»·åˆ—
        close_cols = self.find_closing_price_columns(df)
        logging.debug(f"æ­¥éª¤: Found {len(close_cols)} closing price columns: {close_cols}")
        
        if len(close_cols) < 2:
            logging.warning(f"æ­¥éª¤: Not enough closing price columns found. Need at least 2, found {len(close_cols)}")
            # ä¸ºæ¯ä¸ªè‚¡ç¥¨è¿”å›0æ–œç‡
            for index, row in df.iterrows():
                stock_code = self.get_stock_code(row, df.columns)
                stock_name = self.get_stock_name(row, df.columns)
                key = f"{stock_code} {stock_name}".strip()
                slopes[key] = 0
            return slopes
        
        # å¯¹æ¯ä¸ªè‚¡ç¥¨è®¡ç®—æ–œç‡
        for index, row in df.iterrows():
            stock_code = self.get_stock_code(row, df.columns)
            stock_name = self.get_stock_name(row, df.columns)
            
            # æå–æ”¶ç›˜ä»·åºåˆ—
            closes = []
            valid_columns = []
            
            for col in close_cols:
                val = row.get(col, np.nan)
                if pd.notna(val):
                    # æ¸…ç†æ•°å€¼
                    val_str = str(val).replace(',', '').replace('â€”', '').replace('--', '').strip()
                    if val_str in ["", "NaN", "None", "null"]:
                        continue
                    try:
                        price = float(val_str)
                        if price > 0:
                            closes.append(price)
                            valid_columns.append(col)
                    except Exception as e:
                        logging.debug(f"æ­¥éª¤: Failed to convert value '{val_str}' to float for column {col}: {str(e)}")
                        continue
            
            logging.debug(f"æ­¥éª¤: Stock {stock_code} {stock_name} - Valid columns: {valid_columns}")
            logging.debug(f"æ­¥éª¤: Stock {stock_code} {stock_name} - Raw prices: {closes}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹
            if len(closes) < 2:
                logging.debug(f"æ­¥éª¤: Insufficient price data for {stock_code} {stock_name}, only {len(closes)} valid values")
                key = f"{stock_code} {stock_name}".strip()
                slopes[key] = 0
                continue
            
            # åè½¬é¡ºåºï¼ˆä»æ—§åˆ°æ–°ï¼‰- å› ä¸ºåŒèŠ±é¡ºçš„æ•°æ®é€šå¸¸æ˜¯æœ€è¿‘çš„æ—¥æœŸåœ¨å³è¾¹
            closes = closes[::-1]
            logging.debug(f"æ­¥éª¤: Stock {stock_code} {stock_name} - Reversed prices (old to new): {closes}")
            
            # è®¡ç®—æ–œç‡
            try:
                x = np.arange(len(closes))
                slope, intercept, r_value, p_value, std_err = stats.linregress(x, closes)
                
                # è®¡ç®—æ–œç‡ç™¾åˆ†æ¯”ï¼ˆç›¸å¯¹äºå¹³å‡å€¼ï¼‰
                avg_price = np.mean(closes)
                slope_percentage = (slope / avg_price) * 100 if avg_price != 0 else 0
                
                key = f"{stock_code} {stock_name}".strip()
                slopes[key] = slope_percentage
                logging.debug(f"æ­¥éª¤: Calculated slope for {key}: {slope_percentage:.4f}% (slope={slope:.4f}, avg_price={avg_price:.4f})")
                
            except Exception as e:
                logging.warning(f"æ­¥éª¤: Failed to calculate slope for {stock_code} {stock_name}: {str(e)}")
                key = f"{stock_code} {stock_name}".strip()
                slopes[key] = 0
    
        return slopes

    def read_iwencai_csv_improved(self, file_path):
        """æ”¹è¿›çš„CSVè¯»å–æ–¹æ³•"""
        try:
            # å°è¯•å¤šç§ç¼–ç 
            encodings = ['gbk', 'utf-8', 'gb2312', 'utf-8-sig']
            
            for encoding in encodings:
                try:
                    # è¯»å–åŸå§‹æ•°æ®
                    df_raw = pd.read_csv(file_path, encoding=encoding, header=None, nrows=10)
                    
                    # æ£€æµ‹è¡¨å¤´è¡Œæ•°
                    header_rows = self.detect_header_rows(df_raw)
                    
                    if header_rows == 1:
                        df = pd.read_csv(file_path, encoding=encoding, header=0)
                    else:
                        # å¤šè¡Œè¡¨å¤´å¤„ç†
                        df_raw_full = pd.read_csv(file_path, encoding=encoding, header=None)
                        header_df = df_raw_full.iloc[:header_rows].ffill(axis=1)
                        
                        # æ„å»ºåˆå¹¶åˆ—åï¼ˆä¸Excelæ–¹æ³•ç›¸åŒï¼‰
                        columns = []
                        current_prefix = ""
                        for col in header_df.values.T:
                            col_strs = [str(x).strip() for x in col if str(x) != "nan"]
                            if len(col_strs) == 0:
                                columns.append("")
                                continue
                            
                            if "æ”¶ç›˜ä»·" in col_strs[0]:
                                current_prefix = "æ”¶ç›˜ä»·"
                            elif "5æ—¥å‡çº¿" in col_strs[0] or "å‡çº¿" in col_strs[0]:
                                current_prefix = "5æ—¥å‡çº¿"
                            
                            date_part = col_strs[-1] if len(col_strs) > 1 else col_strs[0]
                            
                            if current_prefix and "undefined" in col_strs[0]:
                                merged = f"{current_prefix}_{date_part}"
                            else:
                                merged = "_".join(col_strs).strip("_")
                            columns.append(merged)
                        
                        df = df_raw_full.iloc[header_rows:].reset_index(drop=True)
                        df.columns = columns
                    
                    # åŸºç¡€æ•°æ®æ¸…æ´—
                    df = self.basic_data_cleaning(df)
                    return df
                    
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    logging.debug(f"Failed to read CSV with encoding {encoding}: {str(e)}")
                    continue
            
            # æ‰€æœ‰ç¼–ç éƒ½å¤±è´¥ï¼Œå°è¯•é»˜è®¤è¯»å–
            return pd.read_csv(file_path)
            
        except Exception as e:
            logging.error(f"Error reading improved CSV: {str(e)}")
            return None

    def auto_detect_iwencai_file_improved(self, file_path):
        """æ”¹è¿›çš„è‡ªåŠ¨æ–‡ä»¶æ£€æµ‹"""
        try:
            # å°è¯•Excel
            df = self.read_iwencai_excel_improved(file_path)
            if df is not None and not df.empty:
                return df
            
            # å°è¯•CSV
            df = self.read_iwencai_csv_improved(file_path)
            if df is not None and not df.empty:
                return df
                
            return None
        except Exception as e:
            logging.error(f"Auto detect improved failed: {str(e)}")
            return None

    def identify_stock_columns(self, df):
        """è¯†åˆ«è‚¡ç¥¨ä»£ç å’Œåç§°åˆ—"""
        df_clean = df.copy()
        
        # æŸ¥æ‰¾ä»£ç åˆ—
        code_patterns = ['ä»£ç ', 'code', 'symbol']
        for col in df_clean.columns:
            col_lower = str(col).lower()
            if any(pattern in col_lower for pattern in code_patterns):
                df_clean = df_clean.rename(columns={col: 'è‚¡ç¥¨ä»£ç '})
                break
        
        # æŸ¥æ‰¾åç§°åˆ—
        name_patterns = ['åç§°', 'name', 'è‚¡ç¥¨åç§°']
        for col in df_clean.columns:
            col_lower = str(col).lower()
            if any(pattern in col_lower for pattern in name_patterns):
                df_clean = df_clean.rename(columns={col: 'è‚¡ç¥¨åç§°'})
                break
        
        return df_clean

    def get_stock_code(self, row, columns):
        code_keywords = ['ä»£ç ', 'code', 'symbol', 'è‚¡ç¥¨ä»£ç ']
        for col in columns:
            if any(keyword in str(col).lower() for keyword in code_keywords):
                return str(row[col]) if pd.notna(row[col]) else f"ä»£ç {row.name}"
        return f"ä»£ç {row.name}"

    def get_stock_name(self, row, columns):
        name_keywords = ['åç§°', 'name', 'è‚¡ç¥¨åç§°']
        for col in columns:
            if any(keyword in str(col).lower() for keyword in name_keywords):
                return str(row[col]) if pd.notna(row[col]) else f"è‚¡ç¥¨{row.name}"
        return f"è‚¡ç¥¨{row.name}"

    # ==================== ç›‘æ§æ§åˆ¶æ–¹æ³• ====================
    def start_monitoring(self, interval_minutes=5):
        if self.is_monitoring:
            st.warning("ç›‘æ§å·²åœ¨è¿è¡Œ")
            return
        self.monitoring_interval = interval_minutes
        self.is_monitoring = True
        self.cycle_count = 1
        st.success(f"ç›‘æ§å¯åŠ¨ï¼Œæ¯{interval_minutes}åˆ†é’Ÿæ‰§è¡Œä¸€æ¬¡")
        self.execute_monitoring_cycle(st.session_state.search_query)
        self.next_execution_time = self.last_execution_time + timedelta(minutes=interval_minutes)

    def stop_monitoring(self):
        self.is_monitoring = False
        self.next_execution_time = None
        st.success("ç›‘æ§å·²åœæ­¢")

    def execute_monitoring_cycle(self, search_query):
        try:
            cycle_start = datetime.now()
            self.last_execution_time = cycle_start
            success = self.one_click_automation_with_refresh(search_query)
            if success:
                data = self.process_downloaded_data()
                if data:
                    self.monitoring_data['timestamps'].append(data['timestamp'])
                    self.monitoring_data['stock_counts'].append(data['stock_count'])
                    self.monitoring_data['stock_lists'].append(data['stock_list'])
                    self.monitoring_data['slope_data'].append(data['slopes'])
                    return True
            return False
        except Exception as e:
            logging.error(f"Error in monitoring cycle: {str(e)}")
            return False

    def update_countdown(self):
        if self.next_execution_time and self.is_monitoring:
            now = datetime.now()
            if now < self.next_execution_time:
                self.countdown_seconds = int((self.next_execution_time - now).total_seconds())
                return True
        self.countdown_seconds = 0
        return False

    def get_countdown_display(self):
        if self.countdown_seconds > 0:
            m = self.countdown_seconds // 60
            s = self.countdown_seconds % 60
            return f"{m:02d}:{s:02d}"
        return "00:00"

    def create_stock_count_chart(self):
        if len(self.monitoring_data['timestamps']) < 1:
            st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ‰§è¡Œä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•")
            return
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=self.monitoring_data['timestamps'],
            y=self.monitoring_data['stock_counts'],
            mode='lines+markers',
            name='è‚¡ç¥¨æ•°é‡',
            line=dict(color='blue', width=2),
            marker=dict(size=8)
        ))
        fig.update_layout(
            title='è‚¡ç¥¨æ•°é‡æ—¶é—´åºåˆ—',
            xaxis_title='æ—¶é—´',
            yaxis_title='è‚¡ç¥¨æ•°é‡',
            template='plotly_white',
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)

    def create_slope_chart(self):
        if not self.monitoring_data['slope_data']:
            st.info("æš‚æ— æ–œç‡æ•°æ®")
            return
        latest_slopes = self.monitoring_data['slope_data'][-1]
        if not latest_slopes:
            return
        sorted_slopes = sorted(latest_slopes.items(), key=lambda x: x[1], reverse=True)
        top_stocks = sorted_slopes[:20]
        if not top_stocks:
            return
        stocks = [item[0] for item in top_stocks]
        slopes = [item[1] for item in top_stocks]
        colors = ['red' if s < 0 else 'green' for s in slopes]
        fig = go.Figure()
        fig.add_trace(go.Bar(
            x=slopes,
            y=stocks,
            orientation='h',
            marker_color=colors,
            text=[f"{s:.4f}" for s in slopes],
            textposition='auto'
        ))
        fig.update_layout(
            title='è‚¡ç¥¨èµ°åŠ¿æ–œç‡æ’åºï¼ˆå‰20åï¼‰',
            xaxis_title='æ–œç‡(%)',
            yaxis_title='è‚¡ç¥¨',
            template='plotly_white',
            height=500
        )
        st.plotly_chart(fig, use_container_width=True)

    def show_monitoring_dashboard(self):
        st.header("ç›‘æ§ä»ªè¡¨æ¿")
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ç›‘æ§æ•°æ®ç‚¹", len(self.monitoring_data['timestamps']))
        with col2:
            if self.monitoring_data['stock_counts']:
                st.metric("æœ€æ–°è‚¡ç¥¨æ•°é‡", self.monitoring_data['stock_counts'][-1])
            else:
                st.metric("æœ€æ–°è‚¡ç¥¨æ•°é‡", 0)
        with col3:
            if self.monitoring_data['timestamps']:
                st.metric("æœ€åæ›´æ–°æ—¶é—´", self.monitoring_data['timestamps'][-1].strftime("%H:%M:%S"))
            else:
                st.metric("æœ€åæ›´æ–°æ—¶é—´", "æ— æ•°æ®")
        with col4:
            if self.is_monitoring:
                self.update_countdown()
                countdown_display = self.get_countdown_display()
                st.metric("ä¸‹æ¬¡æ‰§è¡Œå€’è®¡æ—¶", countdown_display)
            else:
                st.metric("ç›‘æ§çŠ¶æ€", "å·²åœæ­¢")
        
        self.create_stock_count_chart()
        self.create_slope_chart()
        
        if self.monitoring_data['stock_lists']:
            st.subheader("æœ€æ–°è‚¡ç¥¨åˆ—è¡¨")
            latest_df = self.monitoring_data['stock_lists'][-1]
            st.dataframe(latest_df.head(10), use_container_width=True)
            
            # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
            with st.expander("è¯¦ç»†è°ƒè¯•ä¿¡æ¯"):
                st.write("æ•°æ®åˆ—ä¿¡æ¯:")
                st.write(f"æ€»åˆ—æ•°: {len(latest_df.columns)}")
                st.write("æ‰€æœ‰åˆ—å:")
                for i, col in enumerate(latest_df.columns):
                    st.write(f"{i}: '{col}'")
                
                # æ˜¾ç¤ºæ‰¾åˆ°çš„æ”¶ç›˜ä»·åˆ—
                close_cols = self.find_closing_price_columns(latest_df)
                st.write(f"æ‰¾åˆ°çš„æ”¶ç›˜ä»·åˆ— ({len(close_cols)} ä¸ª):")
                for i, col in enumerate(close_cols):
                    st.write(f"  {i}: '{col}'")
                
                # æ˜¾ç¤ºå‰å‡ ä¸ªè‚¡ç¥¨çš„è¯¦ç»†æ•°æ®
                st.write("å‰3ä¸ªè‚¡ç¥¨çš„è¯¦ç»†æ”¶ç›˜ä»·æ•°æ®:")
                for i in range(min(3, len(latest_df))):
                    row = latest_df.iloc[i]
                    stock_code = self.get_stock_code(row, latest_df.columns)
                    stock_name = self.get_stock_name(row, latest_df.columns)
                    
                    st.write(f"**{stock_code} {stock_name}**:")
                    
                    # æ˜¾ç¤ºæ‰€æœ‰æ”¶ç›˜ä»·åˆ—çš„å€¼
                    price_data = []
                    for col in close_cols:
                        val = row.get(col, np.nan)
                        price_data.append(f"'{col}': {val}")
                    
                    st.write("æ”¶ç›˜ä»·æ•°æ®: " + ", ".join(price_data))
                    
                    # æ˜¾ç¤ºè®¡ç®—å‡ºçš„æ–œç‡
                    if self.monitoring_data['slope_data']:
                        latest_slopes = self.monitoring_data['slope_data'][-1]
                        key = f"{stock_code} {stock_name}".strip()
                        slope = latest_slopes.get(key, "æœªæ‰¾åˆ°")
                        st.write(f"è®¡ç®—å‡ºçš„æ–œç‡: {slope}")
                
                # æ˜¾ç¤ºæ‰€æœ‰è‚¡ç¥¨çš„æ–œç‡
                if self.monitoring_data['slope_data']:
                    latest_slopes = self.monitoring_data['slope_data'][-1]
                    st.write("æ‰€æœ‰è‚¡ç¥¨çš„æ–œç‡:")
                    slope_data = []
                    for stock, slope in latest_slopes.items():
                        slope_data.append({"è‚¡ç¥¨": stock, "æ–œç‡(%)": f"{slope:.4f}%"})
                    
                    if slope_data:
                        slope_df = pd.DataFrame(slope_data)
                        st.dataframe(slope_df, use_container_width=True)

    def close(self):
        self.stop_monitoring()
        if self.driver:
            self.driver.quit()
        if os.path.exists(self.profile_dir):
            shutil.rmtree(self.profile_dir)

# ====================== æ•°æ®å¯¼å‡ºåŠŸèƒ½ ======================
def add_export_functionality(monitor):
    """æ·»åŠ æ•°æ®å¯¼å‡ºåŠŸèƒ½"""
    st.sidebar.subheader("æ•°æ®å¯¼å‡º")
    
    if monitor.monitoring_data['stock_lists']:
        latest_data = monitor.monitoring_data['stock_lists'][-1]
        
        # CSVå¯¼å‡º
        csv_data = latest_data.to_csv(index=False).encode('utf-8-sig')
        st.sidebar.download_button(
            label="å¯¼å‡ºCSV",
            data=csv_data,
            file_name=f"stock_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
            mime="text/csv"
        )
        
        # Excelå¯¼å‡º
        excel_buffer = io.BytesIO()
        with pd.ExcelWriter(excel_buffer, engine='openpyxl') as writer:
            latest_data.to_excel(writer, index=False, sheet_name='è‚¡ç¥¨æ•°æ®')
        st.sidebar.download_button(
            label="å¯¼å‡ºExcel",
            data=excel_buffer.getvalue(),
            file_name=f"stock_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )

# ====================== ä¸»å‡½æ•° ======================
def main():
    if 'monitor' not in st.session_state:
        st.session_state.monitor = StockMonitor()
    if 'search_query' not in st.session_state:
        st.session_state.search_query = "ä¸‹å½±çº¿ï¼ä¸Šå½±çº¿ï¼Œå»æ‰stï¼Œå»æ‰åŒ—äº¤æ‰€ï¼Œ5æ—¥å‡çº¿ã€10æ—¥å‡çº¿ã€20æ—¥ã€60æ—¥å‡çº¿å¤šå¤´æ’åˆ—ï¼Œè´¢åŠ¡ç»¼åˆè¯„åˆ†å¤§äº2ï¼Œä¸Šå‡é€šé“ï¼Œ5ä¸ªäº¤æ˜“æ—¥æ¯æ—¥æ”¶ç›˜ä»·"
    
    st.sidebar.title("æ§åˆ¶é¢æ¿")
    
    # æ˜¾ç¤ºç¼“å­˜çŠ¶æ€
    st.sidebar.subheader("å›ºåŒ–åŒ¹é…çŠ¶æ€")
    cache_data = []
    for element_type, cache_info in st.session_state.monitor.cached_selectors.items():
        if cache_info:
            cache_data.append({
                'å…ƒç´ ç±»å‹': element_type,
                'é€‰æ‹©å™¨': cache_info['selector'],
                'æè¿°': cache_info['description']
            })
        else:
            cache_data.append({
                'å…ƒç´ ç±»å‹': element_type,
                'é€‰æ‹©å™¨': 'æœªç¼“å­˜',
                'æè¿°': 'æœªç¼“å­˜'
            })
    st.sidebar.dataframe(pd.DataFrame(cache_data), use_container_width=True)
    
    # ä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•
    if st.sidebar.button("ä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•", type="primary"):
        with st.spinner("æ‰§è¡Œä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•..."):
            if st.session_state.monitor.one_click_automation_with_refresh(st.session_state.search_query):
                data = st.session_state.monitor.process_downloaded_data()
                if data:
                    st.session_state.monitor.monitoring_data['timestamps'].append(data['timestamp'])
                    st.session_state.monitor.monitoring_data['stock_counts'].append(data['stock_count'])
                    st.session_state.monitor.monitoring_data['stock_lists'].append(data['stock_list'])
                    st.session_state.monitor.monitoring_data['slope_data'].append(data['slopes'])
                    st.success("ä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•æˆåŠŸ")
                else:
                    st.error("æ•°æ®å¤„ç†å¤±è´¥")
            else:
                st.error("ä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•å¤±è´¥")
    
    # ç›‘æ§æ§åˆ¶
    st.sidebar.subheader("è‡ªåŠ¨ç›‘æ§")
    interval = st.sidebar.slider("ç›‘æ§é—´éš”(åˆ†é’Ÿ)", 1, 30, 5)
    col1, col2 = st.sidebar.columns(2)
    with col1:
        if st.button("å¼€å§‹ç›‘æ§", type="primary"):
            if not st.session_state.monitor.is_monitoring:
                st.session_state.monitor.start_monitoring(interval)
            else:
                st.warning("ç›‘æ§å·²åœ¨è¿è¡Œ")
    with col2:
        if st.button("åœæ­¢ç›‘æ§"):
            st.session_state.monitor.stop_monitoring()
    
    # æ˜¾ç¤ºç›‘æ§çŠ¶æ€
    if st.session_state.monitor.is_monitoring:
        st.sidebar.success("ç›‘æ§è¿è¡Œä¸­")
        if st.session_state.monitor.next_execution_time:
            st.sidebar.info(f"ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´: {st.session_state.monitor.next_execution_time.strftime('%H:%M:%S')}")
    else:
        st.sidebar.info("ç›‘æ§å·²åœæ­¢")
    
    # æ·»åŠ æ•°æ®å¯¼å‡ºåŠŸèƒ½
    add_export_functionality(st.session_state.monitor)
    
    # æ˜¾ç¤ºç›‘æ§ä»ªè¡¨æ¿
    st.session_state.monitor.show_monitoring_dashboard()
    
    # ä½¿ç”¨æŒ‡å—
    with st.expander("ä½¿ç”¨è¯´æ˜"):
        st.markdown("""
        ### ç³»ç»Ÿç‰¹æ€§
        - **è‡ªåŠ¨é©±åŠ¨ç®¡ç†**: ä½¿ç”¨ webdriver-manager è‡ªåŠ¨ä¸‹è½½å’Œç®¡ç†æµè§ˆå™¨é©±åŠ¨
        - **æ™ºèƒ½ç™»å½•å¤„ç†**: æ‰«ç ç™»å½•åè‡ªåŠ¨æ£€æµ‹å¹¶ç»§ç»­æµç¨‹
        - **å®æ—¶ç›‘æ§**: å¯è®¾ç½®å®šæ—¶è‡ªåŠ¨æ‰§è¡Œ
        - **æ•°æ®å¯¼å‡º**: æ”¯æŒCSVå’ŒExcelæ ¼å¼å¯¼å‡º
        - **æ™ºèƒ½æ•°æ®æ¸…æ´—**: ä¸“é—¨é’ˆå¯¹åŒèŠ±é¡ºé—®è´¢çš„ä¸¤è¡Œè¡¨å¤´æ ¼å¼ä¼˜åŒ–
        - **æ”¹è¿›çš„æ–œç‡è®¡ç®—**: å‡†ç¡®è®¡ç®—5å¤©å†…èµ°åŠ¿çš„æ–œç‡ï¼Œç‰¹åˆ«å¤„ç†undefinedåˆ—
        
        ### æ“ä½œæ­¥éª¤
        1. ç‚¹å‡»"ä¸€é”®è‡ªåŠ¨åŒ–æµ‹è¯•"è¿›è¡Œé¦–æ¬¡æµ‹è¯•
        2. è®¾ç½®ç›‘æ§é—´éš”æ—¶é—´
        3. ç‚¹å‡»"å¼€å§‹ç›‘æ§"å¯åŠ¨è‡ªåŠ¨ç›‘æ§
        4. ç³»ç»Ÿä¼šå®šæœŸè‡ªåŠ¨æ‰§è¡Œå¹¶æ›´æ–°æ•°æ®
        5. ä½¿ç”¨ä¾§è¾¹æ çš„æ•°æ®å¯¼å‡ºåŠŸèƒ½ä¸‹è½½æ•°æ®
        
        ### æ³¨æ„äº‹é¡¹
        - é¦–æ¬¡è¿è¡Œä¼šä¸‹è½½æµè§ˆå™¨é©±åŠ¨ï¼Œè¯·ä¿æŒç½‘ç»œè¿æ¥
        - æ‰«ç ç™»å½•åè¯·å‹¿å…³é—­æµè§ˆå™¨çª—å£
        - å¦‚éœ€åœæ­¢ç›‘æ§ï¼Œè¯·ç‚¹å‡»"åœæ­¢ç›‘æ§"æŒ‰é’®
        - ä¸‹è½½çš„æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åœ¨ä¸´æ—¶ç›®å½•ï¼Œå¯é€šè¿‡å¯¼å‡ºåŠŸèƒ½ä¿å­˜åˆ°æœ¬åœ°
        - ç³»ç»Ÿä¸“é—¨ä¼˜åŒ–äº†åŒèŠ±é¡ºé—®è´¢çš„ä¸¤è¡Œè¡¨å¤´æ ¼å¼å¤„ç†
        - ç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ« undefined åˆ—ä½œä¸ºæ”¶ç›˜ä»·æ•°æ®ç”¨äºæ–œç‡è®¡ç®—
        - æŸ¥çœ‹"è¯¦ç»†è°ƒè¯•ä¿¡æ¯"å±•å¼€é¢æ¿å¯ä»¥äº†è§£æ•°æ®è§£æå’Œæ–œç‡è®¡ç®—çš„è¯¦ç»†è¿‡ç¨‹
        """)
    
    # å…³é—­ç³»ç»Ÿ
    st.sidebar.markdown("---")
    if st.sidebar.button("å…³é—­ç³»ç»Ÿ"):
        st.session_state.monitor.close()
        st.sidebar.success("ç³»ç»Ÿå·²å…³é—­")
    
    # ç›‘æ§å¾ªç¯
    if st.session_state.monitor.is_monitoring:
        now = datetime.now()
        if now >= st.session_state.monitor.next_execution_time:
            st.session_state.monitor.execute_monitoring_cycle(st.session_state.search_query)
            st.session_state.monitor.cycle_count += 1
            st.session_state.monitor.next_execution_time = datetime.now() + timedelta(minutes=st.session_state.monitor.monitoring_interval)
        st.session_state.monitor.update_countdown()
        time.sleep(1)
        st.rerun()

if __name__ == "__main__":
    main()